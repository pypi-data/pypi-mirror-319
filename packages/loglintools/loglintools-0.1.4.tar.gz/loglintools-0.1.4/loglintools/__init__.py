def names():
    print(''' q1() -  код, q1_th() - теория
    q1 - Наивное умножение матрицы на вектор и умножение матриц
    q2 - Иерархия памяти, план кеша и LRU, промахи в обращении к кешу
    q3 - Алгоритм Штрассена
    q4 - Собственные векторы, собственные значения (важность, Google PageRank)
    q5 - Разложение Шура и QR-алгоритм
    q6 - Степенной метод
    q7 - Круги Гершгорина
    q8 - Разложение Шура, теорема Шура
    q9 - Нормальные матрицы, эрмитовы матрицы, унитарно диагонализуемые матрицы, верхне-гессенбергова форма матриц
    q10 - Спектр и псевдоспектр
    q11 - Неявный QR алгоритм (со сдвигами)
    q12 - Алгоритм на основе стратегии "разделяй и властвуй"
    q13 - Разреженные матрицы, форматы хранения разреженных матриц, прямые методы для решения больших разреженных систем
    q14 - Обыкновенные дифференциальные уравнения, задача Коши
    q15 - Локальная, глобальная ошибки
    q16 - Метод центральной разности
    q17 - Метод Эйлера
    q18 - Метод предиктора-корректора
    q19 - Метод Рунге-Кутты 1-4 порядков
    q20 - Методы Адамса-Мултона, методы Адамса-Бэшфорта
    q21 - Метод Милна
    q22 - Согласованность, устойчивость, сходимость, условия устойчивости
    q23 - Моделирование волны с использованием математических инструментов (амплитуда, период, длина волны, частота, Герц, дискретизация, частота дискретизации, фаза, угловая частота)
    q24 - Дискретное преобразование Фурье, обратное дискретное преобразование Фурье их ограничения, симметрии в дискретном преобразовании Фурье
    q25 - Быстрое преобразование Фурье, его принципы, фильтрация сигнала с использованием быстрого преобразования Фурье
    q26 - Операции свёртки, связь с быстрым преобразованием Фурье, операции дискретной свёртки
    q27 - Дискретная свёртка и Тёплицевы матрицы (Ганкелевы матрицы)
    q28 - Циркулянтные матрицы. Матрицы Фурье.
    q29 - Быстрый матвек с циркулянтом''')

def q5():
    print('''# QR-разложение с использованием Грама-Шмидта
def gram_schmidt(A):
    """
    QR разложение
    """
    # Инициализация матриц Q и R
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    for j in range(n):
        v = A[:, j]

        # Ортогонализация текущего вектора
        for i in range(j):
            R[i, j] = Q[:, i] @ A[:, j]
            v = v - R[i, j] * Q[:, i]
        # Нормализация вектора
        R[j, j] = sum(i**2 for i in v) ** 0.5
        Q[:, j] = [i / R[j, j] for i in v]

    return Q, R
A = np.array([[1, 2, 3],
       [2, 3, 4],
       [3, 4, 4]])
Q, R = gram_schmidt(A)


#qr - алгоритм
def QR_method(A, accuracy=0.001):
    Q_final = np.eye(A.shape[0])  # Инициализация единичной матрицы
    Q_list = []

    while np.triu(A, 1).max() > accuracy:
        Q, R = gram_schmidt(A)
        Q_list.append(Q)
        A = R @ Q
        Q_final = Q_final @ Q  # Постепенное обновление итоговой матрицы Q

    return A, np.diag(A), [Q_final[:, i] for i in range(Q_final.shape[1])]

A, nums, vecs = QR_method(A)

#qr - алгоритм библиотечный
def qr_algorithm(A, iter_ = 100):
    n = A.shape[0]
    Q_accumulated = np.eye(n)

    for _ in range(iter_):
        # QR-разложение
        Q, R = np.linalg.qr(A)
        # Обновление A
        A = R @ Q
        # Накопление Q
        Q_accumulated = Q_accumulated @ Q

    eigenvalues = np.diag(A)
    eigenvectors = Q_accumulated
    return A, eigenvalues, eigenvectors

A, eigenvalues, eigenvectors = qr_algorithm(A)''')
    
def q5_th():
    print('''$\LargeРазложение\spaceШура$
- Нужно найти унитарную матрицу $U$ и верхнетреугольную матрицу $T$, такие что для данной матрице $A$ выполнено

$$ A = U T U^*. $$
  * Собственные значения матрицы $A$ находятся на диагонали матрицы $T$.

 **Не путайте** QR алгоритм и QR разложение!

- QR разложение – это представление матрицы в виде произведения двух матриц, а QR алгоритм использует QR разложение для вычисления разложения Шура.

**Путь к QR алгоритму**

Рассмотрим выражение

$$A = Q T Q^*,$$

и перепишем его в виде

$$
   Q T = A Q.
$$

Слева замечаем QR разложение матрицы $AQ$.

Используем его чтобы записать одну итерацию метода неподвижной точки для разложения Шура.

**Вывод QR алгоритма из уравнения неподвижной точки**

Запишем следующий итерационный процесс

$$
    Q_{k+1} R_{k+1} = A Q_k, \quad Q_{k+1}^* A = R_{k+1} Q^*_k
$$

Введём новую матрицу

$$A_k = Q^* _k A Q_k = Q^*_k Q_{k+1} R_{k+1} = \widehat{Q}_k R_{k+1}$$

тогда аппроксимация для $A_{k+1}$ имеет вид

$$A_{k+1} = Q^*_{k+1} A Q_{k+1} = ( Q_{k+1}^* A = R_{k+1} Q^*_k)  = R_{k+1} \widehat{Q}_k.$$

Итак, мы получили стандартную форму записи QR алгоритма.

Финальные формулы обычно записывают в **QRRQ**-форме:

1. Инициализируем $A_0 = A$.
2. Вычислим QR разложение матрицы $A_k$: $A_k = Q_k R_k$.
3. Обновим аппроксимацию $A_{k+1} = R_k Q_k$.

Продолжаем итерации пока $A_k$ не станет достаточно треугольной (например, норма подматрицы под главной диагональю не станет достаточно мала).

**Что известно о сходимости и сложности**

**Утверждение**

Матрицы $A_k$ унитарно подобны матрице $A$

$$A_k = Q^*_{k-1} A_{k-1} Q_{k-1} = (Q_{k-1} \ldots Q_1)^* A (Q_{k-1} \ldots Q_1)$$

а произведение унитарных матриц – унитарная матрица.

Сложность одной итерации $\mathscr{O}(n^3)$, если используется QR разложение для общего случая.

Мы ожидаем, что $A_k$ будет **очень близка к треугольной матрице** для достаточно большого $k$.

**Сходимость и сложность QR алгоритма**

- QR алгоритм сходится от первого диагонального элемента к последнему.

- По крайней мере 2-3 итерации необходимо для определения каждого диагонального элемента матрицы $T$.

- Каждый шаг состоит в вычислении QR разложения и одного произведения двух матриц, в результате имеем сложность $\mathscr{O}(n^3)$.

**Q**: означает ли это итоговую сложность $\mathscr{O}(n^4)$?

**A**: к счастью, нет!

- Мы можем ускорить QR алгоритм, используя сдвиги, поскольку матрица $A_k - \lambda I$ имеет те же векторы Шура (столбцы матрицы $U$).''')
    
def q4_th():
    print('''Что такое собственный вектор?

**Определение**. Вектор $x \neq 0$ называется собственным для квадратной матрицы A, если найдётся такое число $\lambda$, что $$Ax = \lambda x$$


Число $\lambda$ называется $\it{собственным}$ значением.

Так как матрица $A - \lambda I$ должна иметь нетривиальное ядро (что такое ядро?), собственные значения являются корнями характеристического полинома $$det(A - \lambda I) = 0$$

**Важность**

$\it\text{Собственные значения – это частоты выбраций}$

Обычно вычисление собственных значений и собственных векторов необходимо для изучения:

* вибраций в механических структурах
* снижения сложности моделей сложных систем


**Google PageRank**

Одна из самых известных задач, сводящихся к вычислению собственного вектора, – это задача вычисления Google PageRank.

* Задача состои в ранжировании веб-страницы: какие из них являются важными, а какие нет
* В интернете страницы ссылаются друг на друга
* PageRank определяется рекурсивно.

  Обозначим $p_i$ за важность $i$-ой страницы. Тогда определим эту важность как усреднённую важность всех страниц, которые ссылаются на данную страницу. Это определение приводит к следующей линейной системе $$p_i = \sum_{j \in N(i)}\frac{p_j}{L(j)},$$



  где

  * $L(j)$ – число исходящих ссылок с $j$-ой страницы,
  * $N(i)$– число соседей $i$-ой страницы.

  Это может быть записано следующим образом $$p = Gp,   G_{ij} = \frac{1}{L(j)}$$

  

  или как задача на собственные значения $$Gp = 1p$$


  то есть мы уже знаем, что у матрицы $G$ есть собственное значение равное $1$. Заметим, что $G$ – левостохастичная матрица, то есть сумма в каждом столбце равна $1$.''')
    
    
def q3_th():
    print('''Алгоритм Штрассена — это эффективный алгоритм умножения квадратных матриц, снижающий сложность с $O(n^3)$ до $O(n^{log_27}) \approx O(n^{2.81})$. В стандартном методе умножения матриц используется 8 умножений подматриц, что приводит к сложности  $O(n^3)$. Алгоритм Штрассена заменяет 8 умножений на 7,поэтому сложность становится равной  $O(n^{log_27})$

Метод Штрассена становится быстрее наивного алгоритма, если

$$2n^3>7n^{log_27},$$ $$n>667$$''')
    
def q3():
    print('''def strassen_multiply(A, B):
        n = A.shape[0]

        # Базовый случай: умножение 1x1 матриц -> база рекурсии
        if n == 1:
            return A * B

        # Разделение матриц на блоки
        mid = n // 2
        A11, A12, A21, A22 = A[:mid, :mid], A[:mid, mid:], A[mid:, :mid], A[mid:, mid:]
        B11, B12, B21, B22 = B[:mid, :mid], B[:mid, mid:], B[mid:, :mid], B[mid:, mid:]

        # Вычисление 7 промежуточных матриц
        M1 = strassen_multiply(A11 + A22, B11 + B22)
        M2 = strassen_multiply(A21 + A22, B11)
        M3 = strassen_multiply(A11, B12 - B22)
        M4 = strassen_multiply(A22, B21 - B11)
        M5 = strassen_multiply(A11 + A12, B22)
        M6 = strassen_multiply(A21 - A11,B11 + B12)
        M7 = strassen_multiply(A12 - A22, B21 + B22)

        # Сборка результирующей матрицы
        C11 = M1 +M4 - M5 + M7
        C12 = M3 + M5
        C21 = M2 + M4
        C22 = M1 + M3 - M2 + M6

        # Объединение блоков в одну матрицу
        C = np.vstack((np.hstack((C11, C12)), np.hstack((C21, C22))))
        return C

    A = np.array([[1, 2.4, 3, 4], [5, 6.8, 7, 8], [9.5, 10, 11, 12.7], [13.5, 14, 15, 16]])
    B = np.array([[1, 15, 14, 13], [1, 11.4, 10, 9], [8, 72, 6, 5], [4, 3.5, 2, 1]])
    C = strassen_multiply(A, B)
    print("Результат умножения матриц:")
    print(C)
    ''')

         

def q1():
    print('''**Определение**. Произведение матрицы $A$ размера $n×k$ и матрицы $B$ размера $k×m$– это матрица $C$ размера $n×m$ такая что её элементы записываются как $$c_{ij}=∑_{s=1}^{k}a_{is}b_{sj},i=1,…,n,j=1,…,m$$

Для $m=k=n$ сложность наивного алгоритма составляет $2n^3−n^2=O(n^3)$:

Почему рукописная(наивная) реализация такая медленная?

1) не используется параллелилизм

2) не используются преимущества быстрой памяти, в целом архитектуры памяти

**Определение**. Произведение матрицы $A$ размера $n×k$ и вектора $B$ размера $1×k$– это вектор $C$ длины $n$, такой, что его элементы записываются как $$c_{i}=∑_{j=1}^{k}a_{ij}b_{j},i=1,…,n$$''')
    
def q1_th():
    print('''def matmul(a, b): #наивное перемножение матриц
    n = a.shape[0]
    k = a.shape[1]
    m = b.shape[1]
    c = np.zeros((n, m))
    for i in range(n):
        for j in range(m):
            for s in range(k):
                c[i, j] += a[i, s] * b[s, j]
    return c


    def mat_vec_mult(matrix, vector): # Наивное перемножение матрицы на вектор
        num_rows = len(matrix)
        num_cols = len(matrix[0])
        result = [0] * num_rows

        for i in range(num_rows):
            for j in range(num_cols):
                result[i] += matrix[i,j] * vector[j]

        return result


    mat_vec_mult(np.array([[1,2],[2,3],[4,7]]),[4,5]), matmul(np.array([[1,2],[2,3]]),np.array([[1,2],[2,3]]))''')
    
def q2():
    print('''from collections import OrderedDict

    class LRUCache:
        def __init__(self, capacity: int):
            """
            Инициализация кэша с заданной ёмкостью.
            """
            self.cache = OrderedDict()
            self.capacity = capacity

        def get(self, key: int) -> int:
            """
            Получить значение из кэша по ключу.
            Если ключа нет, вернуть -1.
            """
            if key in self.cache:
                # Переместить используемый элемент в конец (считается недавно использованным)
                self.cache.move_to_end(key)
                return self.cache[key]
            return -1

        def put(self, key: int, value: int):
            """
            Добавить элемент в кэш. Если кэш заполнен, удалить наименее используемый элемент.
            """
            if key in self.cache:
                # Если ключ уже существует, обновить значение и переместить в конец
                self.cache.move_to_end(key)
            self.cache[key] = value
            if len(self.cache) > self.capacity:
                # Удалить первый (наименее недавно использованный) элемент
                self.cache.popitem(last=False)

    # Пример использования
    cache = LRUCache(2)

    # Операции
    cache.put(1, 1)  # Кэш: {1: 1}
    cache.put(2, 2)  # Кэш: {1: 1, 2: 2}
    print(cache.get(1))  # Вернет 1, Кэш: {2: 2, 1: 1}
    cache.put(3, 3)  # Кэш: {1: 1, 3: 3} (удален 2)
    print(cache.get(2))  # Вернет -1 (так как 2 удален)
    cache.put(4, 4)  # Кэш: {3: 3, 4: 4} (удален 1)
    print(cache.get(1))  # Вернет -1
    print(cache.get(3))  # Вернет 3, Кэш: {4: 4, 3: 3}
    print(cache.get(4))  # Вернет 4, Кэш: {3: 3, 4: 4}''')


def q2_th():
    print('''Иерархия памяти — это способ организации различных типов памяти компьютера так, чтобы ускорить работу процессора. Память делится на уровни по скорости доступа и размеру: быстрые уровни маленькие и дорогие, а медленные — большие и дешевые.

**Уровни иерархии:**

**1. Регистр процессора:**

- Самый верхний уровень.
- Находится внутри процессора.
- Скорость: сверхбыстрая, доступ за один такт процессора.
- Объем: крошечный (несколько килобайт).
- Стоимость: очень высокая.

**2. Кэш-память процессора (CPU Cache):**
Состоит из 3 уровней:
- L1 (уровень 1):
  - Самая быстрая и дорогая кэш-память.
  - Очень маленький объем (16–128 КБ).
-L2 (уровень 2):
  - Чуть медленнее, но больше (256 КБ – несколько МБ).
- L3 (уровень 3):
  - Медленнее L1 и L2, общий для всех ядер процессора.
  - Объем до десятков МБ.
- Назначение: хранение данных, часто используемых процессором, для минимизации задержек.

**3. Оперативная память (RAM):**

- Скорость: медленнее кэша, но быстрее SSD.
- Объем: значительно больше (гигабайты).
- Стоимость: относительно дорогая.
- Используется для хранения данных и инструкций программ во время выполнения.

**4. Твердотельные накопители (Solid State Drives):**

- Включают неэнергозависимую флэш-память.
- Скорость: медленнее RAM, но быстрее, чем механические жесткие диски.
- Объем: большие (терабайты).
- Стоимость: средняя.
- Используются для долговременного хранения данных.
- Механические жесткие диски (HDD):

**5. Самый нижний уровень.**
- Скорость: самая медленная.
- Объем: очень большой (терабайты).
- Стоимость: самая низкая.
- Используются для долговременного хранения данных, к которым доступ требуется редко.


**План кеша (Cache Planning)**
Кэш работает как промежуточный буфер между процессором и оперативной памятью для ускорения доступа к часто используемым данным. Процесс организации кэша включает следующие аспекты:

**1. Кэш-линии:**

- Данные организуются в блоки фиксированного размера (обычно 32–128 байт).
- При кэшировании загружается вся кэш-линия, а не только отдельный байт.

**2. Ассоциативность кэша:**

- Определяет, как строки памяти сопоставляются с блоками в кэше.
  - Прямое отображение: каждая строка памяти может храниться только в определенном блоке кэша.
  - Полностью ассоциативный кэш: каждая строка памяти может находиться в любом блоке кэша.
  - N-канальный ассоциативный кэш: компромисс между двумя подходами.
  
**3. Алгоритмы замещения:**

- Когда кэш заполняется, нужно освободить место для новых данных.
- Пример: LRU (Least Recently Used), FIFO (First In, First Out), Random Replacement.


**Алгоритм LRU (Least Recently Used)**
LRU — один из самых распространенных алгоритмов замещения данных в кэше.

**Принцип работы:**

- При кэш-промахе (отсутствие данных в кэше) заменяется тот блок данных, который дольше всех не использовался.
- Данные, к которым был последний доступ, считаются самыми "свежими".

**Реализация:**

- Используется структура данных (обычно связанный список или стек).

**При каждом доступе к данным:**

- Если данные уже в кэше — переместить их в начало списка.
- Если данных нет в кэше:
- Если кэш заполнен, удалить последний элемент списка (самый "старый").
- Добавить новые данные в начало списка.

**Плюсы:**

- Эффективно для данных с локальностью запросов.
- Снижает частоту промахов.

**Минусы:**

Увеличенные затраты на обновление структуры (в худшем случае $\mathscr{O}(n)$)''')
