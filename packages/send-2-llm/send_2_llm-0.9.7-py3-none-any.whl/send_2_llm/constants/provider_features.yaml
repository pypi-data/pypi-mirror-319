# Provider and model features configuration

providers:
  perplexity:
    features:
      streaming: true
      function_calling: true
      web_search: true
      citations: true
      related_questions: true
    models:
      llama-3.1-sonar-small-128k-online:
        features:
          streaming: true
          function_calling: true
          web_search: true
          citations: true
          related_questions: true
          context_length: 127072
          parameter_count: 8
          model_type: chat
      llama-3.1-sonar-large-128k-online:
        features:
          streaming: true
          function_calling: true
          web_search: true
          citations: true
          related_questions: true
          context_length: 127072
          parameter_count: 70
          model_type: chat
      llama-3.1-sonar-huge-128k-online:
        features:
          streaming: true
          function_calling: true
          web_search: true
          citations: true
          related_questions: true
          context_length: 127072
          parameter_count: 405
          model_type: chat
      pplx-7b-online:
        features:
          streaming: true
          function_calling: true
          web_search: true
          citations: true
          related_questions: true
          context_length: 4096
      pplx-70b-online:
        features:
          streaming: true
          function_calling: true
          web_search: true
          citations: true
          related_questions: true
          context_length: 4096
      pplx-7b-chat:
        features:
          streaming: true
          function_calling: true
          web_search: false
          citations: false
          related_questions: false
          context_length: 4096
      pplx-70b-chat:
        features:
          streaming: true
          function_calling: true
          web_search: false
          citations: false
          related_questions: false
          context_length: 4096
      llama-2-70b-chat:
        features:
          streaming: true
          function_calling: true
          web_search: false
          citations: false
          related_questions: false
          context_length: 4096
      mixtral-8x7b-chat:
        features:
          streaming: true
          function_calling: true
          web_search: false
          citations: false
          related_questions: false
          context_length: 4096
      codellama-34b-instruct:
        features:
          streaming: true
          function_calling: true
          web_search: false
          citations: false
          related_questions: false
          context_length: 4096
      mistral-7b-instruct:
        features:
          streaming: true
          function_calling: true
          web_search: false
          citations: false
          related_questions: false
          context_length: 4096

  openai:
    models:
      gpt-4o:
        features:
          streaming: true
          function_calling: true
          vision: true
  
  anthropic:
    models:
      claude-3.5-sonnet:
        features:
          streaming: true
          function_calling: true
          vision: true
          prompt_caching: true
  
  deepseek:
    models:
      deepseek-chat:
        features:
          streaming: true
          function_calling: true
          prompt_caching: true
  
  gemini:
    models:
      gemini-1.5-pro:
        features:
          streaming: true
          function_calling: true
          vision: true
            
  together:
    models:
      deepseek-chat:
        features:
          streaming: true
          function_calling: true
      
      mistral-large:
        features:
          streaming: true
          function_calling: true

# Model aliases and mappings
model_aliases:
  "deepseek-chat":
    direct: "deepseek/deepseek-chat"
    together: "together/deepseek-chat"
  
  "mistral-large":
    direct: "mistral/mistral-large"
    together: "together/mistral-large" 