{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsecnn_with_prediction_model import *\n",
    "from losses import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer, Lambda, Convolution2D, Concatenate, Add, Multiply, MaxPooling2D, ReLU, Activation\n",
    "from keras.models import Model, Input\n",
    "\n",
    "\n",
    "##### SPARSECONV MODEL #####\n",
    "\n",
    "\n",
    "###  A simple Bias-only layer implementation\n",
    "###   we assume a channel-last layout\n",
    "class Bias(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Bias, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                            shape=(input_shape[1],input_shape[2],input_shape[3]),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "\n",
    "        super(Bias, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.bias\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "        \n",
    "    \n",
    "###  Returns a sparse convolution block as\n",
    "###  described in \n",
    "###  Jonas Uhrig et al. \"Sparsity Invariant CNNs\", Figure 2 (right)\n",
    "def sparse_conv_block( I, M, ksize, depth ):\n",
    "\n",
    "    IM = Multiply( )([I,M] )\n",
    "\n",
    "    IMc = Convolution2D( depth, ksize, padding='same', use_bias=False, activation=None) ( IM )\n",
    "\n",
    "    # A hack to convolve with a fixed \"ones\" kernel\n",
    "    Mc = Convolution2D( 1, ksize, padding='same', use_bias=False, activation=None, \n",
    "                        kernel_initializer = 'ones',\n",
    "                        trainable=False) ( M )\n",
    "\n",
    "\n",
    "    Inorm = Lambda( lambda x: x[0]/(x[1]+1E-5) )( [IMc,Mc] )\n",
    "    InormB = Bias( )(Inorm)\n",
    "\n",
    "    #Mpooled = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(M)\n",
    "    Mpooled = MaxPooling2D(pool_size=ksize, strides=(1,1), padding='same')(M)\n",
    "\n",
    "    return InormB, Mpooled\n",
    "\n",
    "    \n",
    "def create_sparseconv_256_model( input_layer=None ):\n",
    "    \n",
    "    if input_layer is None:\n",
    "        input_data = Input( shape=(256,256,2) )\n",
    "    else:\n",
    "        input_data = input_layer\n",
    "        \n",
    "    I0 = Lambda( lambda x: K.expand_dims(x[:,:,:,0],axis=-1), name=\"I0\" )( input_data )\n",
    "    M0 = Lambda( lambda x: K.expand_dims(x[:,:,:,1],axis=-1), name=\"M0\" )( input_data )\n",
    "    \n",
    "    I,M = sparse_conv_block( I0, M0, (11,11), 16)\n",
    "    I = Activation('sigmoid')( I )\n",
    "    I,M = sparse_conv_block( I, M, (7,7), 16)\n",
    "    I = Activation('sigmoid')( I )\n",
    "    I,M = sparse_conv_block( I, M, (5,5), 16)\n",
    "    I = Activation('sigmoid')( I )\n",
    "    I,M = sparse_conv_block( I, M, (3,3), 16)\n",
    "    I = Activation('sigmoid')( I )\n",
    "    I,M = sparse_conv_block( I, M, (3,3), 16)\n",
    "    I = Activation('sigmoid')( I )\n",
    "\n",
    "    I,M = sparse_conv_block( I, M, (1,1), 1)\n",
    "    O = Activation('linear', name=\"sc_out\")( I )\n",
    "    \n",
    "    model = Model(inputs=input_data, outputs=O )    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "##### MODEL WITH PREDICTION (prev, curr, next)#####\n",
    "\n",
    "def compute_data_mask( data ):\n",
    "    \n",
    "    sparse_data = tf.expand_dims(data, axis=-1)\n",
    "    mask = tf.cast( tf.math.logical_not( tf.math.is_nan(sparse_data)), tf.float32)\n",
    "    \n",
    "    sparse_data = tf.math.multiply_no_nan(sparse_data, mask) # NaN * 0 = 0\n",
    "    \n",
    "    return tf.concat((sparse_data, mask), axis=3)\n",
    "\n",
    "\n",
    "def spec_predict( l, phdiff ):\n",
    "    \n",
    "    l_spec = tf.signal.fft2d(tf.complex(l[:,:,:,0], 0.0))\n",
    "    l_spec =  tf.multiply(l_spec, phdiff)\n",
    "    \n",
    "    l_out = tf.math.real(tf.signal.ifft2d(l_spec)) \n",
    "    l_out = tf.expand_dims(l_out, axis=-1)\n",
    "    \n",
    "    return l_out\n",
    "    \n",
    "\n",
    "def create_model_with_prediction( sparsecnn_trainable=False ):\n",
    "    \n",
    "    model_sparsecnn = create_sparseconv_256_model()\n",
    "\n",
    "    if not sparsecnn_trainable:\n",
    "        for l in model_sparsecnn.layers:\n",
    "            l.trainable = False\n",
    "    \n",
    "    input_data = Input( shape=(256,256,3) )\n",
    "    input_ph_diff_matrix = Input( shape=(256,256,4) ) # prev_real, prev_imag, next_real, next_imag\n",
    "    \n",
    "    IpMp = Lambda( lambda x: compute_data_mask(x[:,:,:,0]), name=\"IpMp\" )( input_data )\n",
    "    IcMc = Lambda( lambda x: compute_data_mask(x[:,:,:,1]), name=\"IcMc\" )( input_data )\n",
    "    InMn = Lambda( lambda x: compute_data_mask(x[:,:,:,2]), name=\"InMn\" )( input_data )\n",
    "    \n",
    "    Op = model_sparsecnn( IpMp )\n",
    "    Oc = model_sparsecnn( IcMc )\n",
    "    On = model_sparsecnn( InMn )\n",
    "    \n",
    "    ph_diff_prev = Lambda( lambda x: tf.complex(x[:,:,:,0], x[:,:,:,1])) (input_ph_diff_matrix)\n",
    "    ph_diff_next = Lambda( lambda x: tf.complex(x[:,:,:,2], x[:,:,:,3])) (input_ph_diff_matrix)\n",
    "    \n",
    "    Oc = Lambda( lambda x: x, name=\"curr\" )( Oc )\n",
    "    \n",
    "    Op_pred = Lambda( lambda x: spec_predict( x[0], x[1]), name=\"predict_prev\" )( [Op, ph_diff_prev] )\n",
    "    On_pred = Lambda( lambda x: spec_predict( x[0], x[1]), name=\"predict_next\" )( [On, ph_diff_next] )\n",
    "    \n",
    "    Oc = Concatenate()([Op_pred, Oc, On_pred])\n",
    "        \n",
    "    Oc = Convolution2D( 16, (5,5), padding='same', use_bias=True, activation=\"sigmoid\") ( Oc )\n",
    "    Oc = Convolution2D( 16, (3,3), padding='same', use_bias=True, activation=\"sigmoid\") ( Oc )\n",
    "    Oc = Convolution2D( 8, (3,3), padding='same', use_bias=True, activation=\"sigmoid\") ( Oc )\n",
    "    Oc = Convolution2D( 1, (1,1), padding='same', use_bias=True, activation=\"linear\") ( Oc )\n",
    "        \n",
    "    model = Model(inputs = [input_data,input_ph_diff_matrix], outputs=Oc )\n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n",
    "# create model\n",
    "model = create_model_with_prediction()\n",
    "print(model.summary())\n",
    "\n",
    "# load weights\n",
    "model.load_weights('modeldata/prediction_v1_2020-09-22_16-07-17.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction test\n",
    "import h5py\n",
    "import numpy as np\n",
    "from SparseSeriesDataGenerator import SparseSeriesDataGenerator\n",
    "\n",
    "h5_data = h5py.File('data/waves_256x256_7fps_pred.h5', 'r')\n",
    "sceneries  = [k for k in h5_data.keys()]\n",
    "d0 = h5_data[sceneries[0]]\n",
    "\n",
    "dt = np.array(d0['dt']).item(0)\n",
    "KxKy = np.array( d0['KxKy'] )\n",
    "angle = np.array(d0['waveangle']).item(0)\n",
    "test_data = d0[\"train\"]\n",
    "\n",
    "test_sampling = (0.03, 0.05)\n",
    "\n",
    "\n",
    "test_generator = SparseSeriesDataGenerator(test_data, test_sampling, KxKy, angle, dt, batch_size=32)\n",
    "\n",
    "x, y_gt = test_generator[0]\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)\n",
    "print(y_gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for idx in range(0, 5 ):\n",
    "    \n",
    "    sparse_data = x[0][idx,:,:,1];\n",
    "    \n",
    "    fig =  plt.figure(figsize=(30, 7))\n",
    "    \n",
    "    fig.add_subplot(1, 3, 1);\n",
    "    plt.pcolor(sparse_data)\n",
    "    #plt.clim(zminmax[0],zminmax[1])\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparse data curr (input)')\n",
    "\n",
    "    '''fig.add_subplot(1, 6, 2)\n",
    "    plt.pcolor(masked_data[idx,:,:,1])\n",
    "    #plt.clim(zminmax[0],zminmax[1])\n",
    "    plt.colorbar()\n",
    "    plt.title('binary mask')'''\n",
    "    \n",
    "    fig.add_subplot(1, 3, 2);\n",
    "    plt.pcolor(y_pred[idx,:,:,0])\n",
    "    #plt.clim(zminmax[0],zminmax[1])\n",
    "    plt.colorbar()\n",
    "    plt.title('network output')\n",
    "    \n",
    "    fig.add_subplot(1, 3, 3)\n",
    "    plt.pcolor(y_gt[idx,:,:,0])\n",
    "    #plt.clim(zminmax[0],zminmax[1])\n",
    "    plt.colorbar()\n",
    "    plt.title('GT curr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}