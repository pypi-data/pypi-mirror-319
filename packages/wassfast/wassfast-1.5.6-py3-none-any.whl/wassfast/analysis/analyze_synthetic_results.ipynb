{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.signal\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CNN_OUT_FILE =  \"/media/fibe/FIO_2018/synth/synth_cnn.nc\" \n",
    "PU_OUT_FILE =  \"/media/fibe/FIO_2018/synth/synth_pu.nc\" \n",
    "GT_FILE = \"/media/fibe/FIO_2018/synth/synth_sequence.h5\"\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def crossings_nonzero_pos2neg(data):\n",
    "    pos = data > 0\n",
    "    return (pos[:-1] & ~pos[1:]).nonzero()[0]\n",
    "\n",
    "def extract_timeserie( data, t ):\n",
    "    print(\" - Computing statistics on the grid center timeserie\")\n",
    "    timeserie = data[:,halfgridsize_i,halfgridsize_j] * 1E-3\n",
    "    timeserie = np.array( timeserie - np.mean(timeserie) )\n",
    "    dt = t[2]-t[1]\n",
    "    print(\"   dt: \",dt)\n",
    "\n",
    "\n",
    "    crossings = crossings_nonzero_pos2neg(timeserie)\n",
    "\n",
    "    dmins = []\n",
    "    dmaxs = []\n",
    "    for ii in range( np.size(crossings)-1 ):\n",
    "        datarange = np.arange(crossings[ii], crossings[ii+1])\n",
    "        data = timeserie[ datarange ]\n",
    "        dmax = np.argmax(data)\n",
    "        dmin = np.argmin(data)\n",
    "        dmins.append( datarange[dmin] )\n",
    "        dmaxs.append( datarange[dmax] )\n",
    "        \n",
    "    waveheights = np.array(timeserie[dmaxs]) - np.array(timeserie[dmins])\n",
    "    q = np.quantile( waveheights, 2.0/3.0)\n",
    "    print(\"   timeserie quantile: \", q)\n",
    "\n",
    "    highestthirdwaves = waveheights[ waveheights>q ]\n",
    "    H13 = np.mean(highestthirdwaves)\n",
    "    print(\"   H1/3: \", H13)\n",
    "    return timeserie, crossings, dmins, dmaxs, H13\n",
    "\n",
    "#plt.savefig(os.path.join(self.scriptpath,\"timeserie.png\"))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_cnn = Dataset( CNN_OUT_FILE )\n",
    "root_pu = Dataset( PU_OUT_FILE )\n",
    "\n",
    "print( root_cnn[\"/Z\"].shape )\n",
    "print( root_pu[\"/Z\"].shape )\n",
    "\n",
    "sequence_start = 16\n",
    "sequence_end = np.min([root_cnn[\"/Z\"].shape[0], root_pu[\"/Z\"].shape[0]])-1\n",
    "\n",
    "Zcnn = root_cnn[\"/Z\"][sequence_start:sequence_end,...]\n",
    "Zpu = root_pu[\"/Z\"][sequence_start:sequence_end,...]\n",
    "\n",
    "f = h5py.File( GT_FILE, \"r\" )\n",
    "Zgt = f[\"/0000/data\"][sequence_start:sequence_end,:,:]*1000.0\n",
    "\n",
    "nsamples = root_cnn[\"/Z\"].shape[0]\n",
    "gridsize = root_cnn[\"/Z\"].shape[1:3]\n",
    "\n",
    "halfgridsize_i = gridsize[0]//2\n",
    "halfgridsize_j = gridsize[1]//2\n",
    "\n",
    "valid_i_start = gridsize[0]//3-35\n",
    "valid_i_end = gridsize[0]//3+36\n",
    "valid_j_start = halfgridsize_j-35\n",
    "valid_j_end = halfgridsize_j+36"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "IDX = 80\n",
    "mask = np.isnan( Zcnn[IDX,:,:])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,3,1)\n",
    "Z = Zgt[IDX,:,:]\n",
    "\n",
    "zmin = np.amin(Z)\n",
    "zmax = np.amax(Z)\n",
    "\n",
    "Z[mask] = np.nan\n",
    "plt.imshow(Z, vmin=zmin, vmax=zmax)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "Z = Zcnn[IDX,:,:]\n",
    "plt.imshow(Z, vmin=zmin, vmax=zmax)\n",
    "plt.subplot(1,3,3)\n",
    "Z = Zpu[IDX,:,:]\n",
    "Z[mask] = np.nan\n",
    "plt.imshow(Z, vmin=zmin, vmax=zmax)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,3,1)\n",
    "Z = Zgt[IDX,valid_i_start:valid_i_end, valid_j_start:valid_j_end]\n",
    "print(\"GT Hs: \", 4*np.std(Z) )\n",
    "print(\"GT :\", np.mean( np.abs(Z-np.mean(Z)) ))\n",
    "plt.imshow(Z, vmin=zmin, vmax=zmax)\n",
    "plt.subplot(1,3,2)\n",
    "Z = Zcnn[IDX,valid_i_start:valid_i_end, valid_j_start:valid_j_end]\n",
    "print(\"CNN Hs: \", 4*np.std(Z) )\n",
    "print(\"CNN :\", np.mean( np.abs(Z-np.mean(Z)) ))\n",
    "plt.imshow(Z, vmin=zmin, vmax=zmax)\n",
    "plt.subplot(1,3,3)\n",
    "Z = Zpu[IDX,valid_i_start:valid_i_end, valid_j_start:valid_j_end]\n",
    "print(\"Pu Hs: \", 4*np.std(Z) )\n",
    "print(\"Pu :\", np.mean( np.abs(Z-np.mean(Z)) ))\n",
    "plt.imshow(Z,vmin=zmin, vmax=zmax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "t = root_cnn[\"/time\"][sequence_start:sequence_end]\n",
    "\n",
    "plt.figure( figsize=(30,10))\n",
    "\n",
    "ST=100\n",
    "ED=400\n",
    "\n",
    "dt = t[2]-t[1]\n",
    "\n",
    "timeserie_gt, crossings, dmins, dmaxs, H13_gt = extract_timeserie( Zgt, t )\n",
    "plt.plot(t[ST:ED], timeserie_gt[ST:ED], \"k\", linewidth=5 )\n",
    "\n",
    "timeserie_cnn, crossings, dmins, dmaxs, H13_cnn = extract_timeserie( Zcnn, t )\n",
    "plt.plot(t[ST:ED], timeserie_cnn[ST:ED], \"b\", linewidth=3 )\n",
    "\n",
    "timeserie_pu, crossings, dmins, dmaxs, H13_pu = extract_timeserie( Zpu, t )\n",
    "plt.plot(t[ST:ED], timeserie_pu[ST:ED], \"r\", linewidth=3 )\n",
    "\n",
    "plt.grid()\n",
    "plt.legend([ \"GT  (H1/3 = %1.3f)\"%H13_gt,\n",
    "             \"CNN (H1/3 = %1.3f)\"%H13_cnn,\n",
    "             \"PU  (H1/3 = %1.3f)\"%H13_pu,\n",
    " ])\n",
    "plt.title(\"Surface Elevation at Grid Center\")\n",
    "plt.xlabel(\"Time (secs.)\")\n",
    "plt.ylabel(\"Height (m)\")\n",
    "\n",
    "\n",
    "print(\"Pearson correlation (CNN vs GT)\")\n",
    "print( np.corrcoef(timeserie_gt, timeserie_cnn) )\n",
    "print(\"Pearson correlation (PU vs GT)\")\n",
    "print( np.corrcoef(timeserie_gt, timeserie_pu) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Zcube_gt = np.array( Zgt[:,valid_i_start:valid_i_end, valid_j_start:valid_j_end] * 1E-3 )\n",
    "Zcube_gt = Zcube_gt - np.mean(Zcube_gt)\n",
    "Hs = 4.0*np.std( Zcube_gt )\n",
    "print(\"GT   Hs: \", Hs)\n",
    "\n",
    "Zcube_cnn = np.array( Zcnn[:,valid_i_start:valid_i_end, valid_j_start:valid_j_end] * 1E-3 )\n",
    "Zcube_cnn = Zcube_cnn - np.mean(Zcube_cnn)\n",
    "Hs = 4.0*np.std( Zcube_cnn) \n",
    "print(\"CNN  Hs: \", Hs)\n",
    "\n",
    "\n",
    "Zcube_pu = np.array( Zpu[:,valid_i_start:valid_i_end, valid_j_start:valid_j_end] * 1E-3 )\n",
    "Zcube_pu = Zcube_pu - np.mean(Zcube_pu)\n",
    "Hs = 4.0*np.std( Zcube_pu )\n",
    "print(\"PU  Hs: \", Hs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Hs_gt = 4.0*np.std( Zcube_gt, axis=(1,2) )\n",
    "Hs_cnn = 4.0*np.std( Zcube_cnn, axis=(1,2)) \n",
    "Hs_pu = 4.0*np.std( Zcube_pu, axis=(1,2) )\n",
    "\n",
    "plt.figure( figsize=(20,10))\n",
    "#plt.plot( Hs_gt, 'k')\n",
    "Hs_error_pu = np.abs( Hs_pu-Hs_gt )\n",
    "Hs_error_cnn = np.abs( Hs_cnn-Hs_gt )\n",
    "plt.plot( Hs_error_pu[:100], 'r')\n",
    "plt.plot( Hs_error_cnn[:100], 'b')\n",
    "plt.grid()\n",
    "plt.legend([\"PU\",\"CNN\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MSE_pu = np.mean( np.square(Zcube_gt - Zcube_pu) )\n",
    "print(\"MSE pu: \", MSE_pu)\n",
    "MSE_cnn = np.mean( np.square(Zcube_gt - Zcube_cnn) )\n",
    "print(\"MSE cnn: \", MSE_cnn)\n",
    "\n",
    "MSE_pu = np.mean( np.square(Zcube_gt - Zcube_pu), axis=(1,2) )\n",
    "print(\"MSE pu: \", MSE_pu)\n",
    "MSE_cnn = np.mean( np.square(Zcube_gt - Zcube_cnn), axis=(1,2) )\n",
    "print(\"MSE cnn: \", MSE_cnn)\n",
    "\n",
    "plt.figure( figsize=(20,10))\n",
    "plt.plot( MSE_pu[:100], 'r')\n",
    "plt.plot( MSE_cnn[:100], 'b')\n",
    "plt.grid()\n",
    "plt.legend([\"PU\",\"CNN\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def compute_omnispec( timeserie, data, dt, valid_samples_i, valid_samples_j ):\n",
    "    NPSEG = 300\n",
    "    f, S = scipy.signal.csd(timeserie, timeserie, 1.0/dt, nperseg=NPSEG )\n",
    "\n",
    "    for ii in tqdm(valid_samples_i):\n",
    "        for jj in valid_samples_j:\n",
    "            timeserie_neigh = data[:,ii,jj] * 1E-3\n",
    "            timeserie_neigh = timeserie_neigh - np.mean(timeserie_neigh)\n",
    "            _, S_neig = scipy.signal.csd(timeserie_neigh, timeserie_neigh, 1.0/dt, nperseg=NPSEG )\n",
    "            S += S_neig\n",
    "\n",
    "    S = S / float( np.size(valid_samples_i)*np.size(valid_samples_j) + 1)\n",
    "    return f,S\n",
    "\n",
    "f,Sgt = compute_omnispec( timeserie_gt, Zgt, dt, np.arange(valid_i_start,valid_i_end), np.arange(valid_j_start, valid_j_end) )\n",
    "f,Scnn = compute_omnispec( timeserie_cnn, Zcnn, dt, np.arange(valid_i_start,valid_i_end), np.arange(valid_j_start, valid_j_end) )\n",
    "f,Spu = compute_omnispec( timeserie_pu, Zpu, dt, np.arange(valid_i_start,valid_i_end), np.arange(valid_j_start, valid_j_end) )\n",
    "\n",
    "topfreq = np.where(f>0.7)[0][0]\n",
    "\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.loglog( f[:topfreq], Sgt[:topfreq], \"k\")\n",
    "plt.loglog( f[:topfreq], Scnn[:topfreq], \"b\")\n",
    "plt.loglog( f[:topfreq], Spu[:topfreq], \"r\")\n",
    "#plt.xticks([1E-2,1E-1,1E0])\n",
    "plt.grid(which='minor')\n",
    "plt.legend([\"GT\",\"CNN\", \"PU\"])\n",
    "plt.ylabel(\"S (m^2s)\")\n",
    "plt.xlabel(\"f_a (1/s)\")\n",
    "plt.title(\"Spectrum (Welch method) averaged in central grid region\")\n",
    "\n",
    "# Compute Hs\n",
    "dFreq = np.gradient( f )\n",
    "m0 = np.sum( Sgt*dFreq )\n",
    "m1 = np.sum( f*Sgt*dFreq )\n",
    "Hm0 = 4.0 * np.sqrt( m0 )\n",
    "print(\"GT   Hm0: \", Hm0)\n",
    "m0 = np.sum( Scnn*dFreq )\n",
    "m1 = np.sum( f*Scnn*dFreq )\n",
    "Hm0 = 4.0 * np.sqrt( m0 )\n",
    "print(\"CNN   Hm0: \", Hm0)\n",
    "m0 = np.sum( Spu*dFreq )\n",
    "m1 = np.sum( f*Spu*dFreq )\n",
    "Hm0 = 4.0 * np.sqrt( m0 )\n",
    "print(\" PU   Hm1: \", Hm0)\n",
    "\n",
    "# Peak frequency\n",
    "pp = f[np.argmax( Sgt )]\n",
    "print(\"   Peak frequency (Hz): \", pp)\n",
    "\n",
    "# Average Period Tm01\n",
    "Tm01 = m0/m1\n",
    "print(\"   Tm01: \", Tm01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(f>1.0)[0][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Z_to_process = Zcnn\n",
    "\n",
    "print(\" - Analyzing space-time 3D spectrum\")\n",
    "Z = Z_to_process[3,:,:]\n",
    "N = Z.shape[0]\n",
    "Nm = int( N/2 )\n",
    "dy = (root_cnn[\"/Y_grid\"][2,0] - root_cnn[\"/Y_grid\"][1,0])/1000.0\n",
    "dx = (root_cnn[\"/X_grid\"][0,2] - root_cnn[\"/X_grid\"][0,1])/1000.0\n",
    "print(\"   grid dx,dy: \", dx,dy)\n",
    "\n",
    "if np.abs( dx-dy ) < 1E-3:\n",
    "    dy = dx  # force dx = dy if very close to avoid numerical errors\n",
    "\n",
    "# Extract a central part of the Zcube\n",
    "N = 120\n",
    "min_freq = 0.25\n",
    "max_freq = 0.7\n",
    "num_plots = 10\n",
    "segments = 5 \n",
    "\n",
    "sequence_length = np.size(timeserie_gt)\n",
    "Nt = int(sequence_length / segments)\n",
    "if Nt%2 > 0:\n",
    "    Nt+=1\n",
    "seg_shift = int(Nt/2)\n",
    "\n",
    "Zcube_mr = int( Z_to_process.shape[1] / 2 )\n",
    "Zcube_mc = int( Z_to_process.shape[2] / 2 )\n",
    "r_start, r_end = Zcube_mr-int(N/2)-20, Zcube_mr+int(N/2)-20+1\n",
    "c_start, c_end = Zcube_mc-int(N/2), Zcube_mc+int(N/2)+1 \n",
    "\n",
    "Nx = r_end - r_start\n",
    "Ny = c_end - c_start\n",
    "print(\"   Nx,Ny,Nt: \",Nx,Ny,Nt)\n",
    "\n",
    "kx_max=(2.0*np.pi/dx)/2.0\n",
    "ky_max=(2.0*np.pi/dy)/2.0\n",
    "f_max= (1.0/dt)/2.0\n",
    "dkx=2.0*np.pi/(dx*np.floor(Nx/2.0)*2.0)\n",
    "dky=2.0*np.pi/(dy*np.floor(Ny/2.0)*2.0)\n",
    "df =1.0/(dt*np.floor(Nt/2.0)*2.0)\n",
    "\n",
    "#print(\"   kx_max, ky_max, f_max, dkx, dky, df: \", kx_max, ky_max, f_max, dkx, dky, df)\n",
    "\n",
    "assert( Nx%2 != 0)\n",
    "assert( Ny%2 != 0)\n",
    "assert( Nt%2 == 0)\n",
    "\n",
    "kx=np.arange(-kx_max,kx_max+dkx,dkx)\n",
    "ky=np.arange(-ky_max,ky_max+dky,dky)\n",
    "\n",
    "if Nt%2==0:\n",
    "    f=np.arange(-f_max, f_max, df)\n",
    "else:\n",
    "    f=np.arange(-f_max, f_max+df, df)\n",
    "\n",
    "KX, KY = np.meshgrid( kx, ky )\n",
    "dkx=kx[3]-kx[2]\n",
    "dky=ky[3]-ky[2]\n",
    "KXY=np.sqrt(KX**2+KY**2)\n",
    "print(\"   kdx, dky: \", dkx, dky)\n",
    "\n",
    "\n",
    "hanningx = scipy.signal.windows.hann(KX.shape[0])\n",
    "hanningy = scipy.signal.windows.hann(KX.shape[1])\n",
    "hanningt = scipy.signal.windows.hann(Nt)\n",
    "\n",
    "Win3Dhann = np.tile( np.expand_dims( hanningx, axis=-1) * hanningy, (Nt,1,1) ) *  np.tile( np.expand_dims( np.expand_dims( hanningt, axis=-1 ), axis=-1 ), (1, KX.shape[0], KX.shape[1]) )\n",
    "assert( KX.shape == Win3Dhann.shape[1:] )\n",
    "\n",
    "#  window correction factors\n",
    "wc2x = 1.0/np.mean(hanningx**2)\n",
    "wc2y = 1.0/np.mean(hanningy**2)\n",
    "wc2t = 1.0/np.mean(hanningt**2)\n",
    "wc2xy  = wc2x *wc2y\n",
    "wc2xyt = wc2xy*wc2t\n",
    "\n",
    "print(\"   dt, dkx, dky, df: \",dt, dkx, dky, df)\n",
    "\n",
    "# Fix for rounding errors\n",
    "r_end = r_start + Win3Dhann.shape[1]\n",
    "c_end = c_start + Win3Dhann.shape[2]\n",
    "\n",
    "S_welch = np.zeros_like( Win3Dhann )\n",
    "n_samples = 0\n",
    "print(\"   Computing 3D FFT via Welch's method... \", end=\"\")\n",
    "for ii in tqdm(range(segments*2)):\n",
    "    #print(\"Welch sample %d/%d\"%(ii+1,segments*2))\n",
    "    Zcube_small = np.array( Z_to_process[(ii*seg_shift):(ii*seg_shift+Nt), r_start:r_end, c_start:c_end ] )\n",
    "    if Zcube_small.shape[0] != Nt:\n",
    "        break\n",
    "        \n",
    "    Zcube_w = (Zcube_small - np.mean(Zcube_small) ) * Win3Dhann\n",
    "    \n",
    "    S = np.fft.fftshift( np.fft.fftn( Zcube_w, norm=\"ortho\" ) )\n",
    "    S /= (S.shape[0]*S.shape[1]*S.shape[2])\n",
    "    S = np.abs(S)**2 / (dkx*dky*df)\n",
    "    #-----------------------------\n",
    "    #%%%%% corrects for window\n",
    "    #----------------------------\n",
    "    #%% FABIEN\n",
    "    S *= wc2xyt\n",
    "    \n",
    "    # Store\n",
    "    S_welch += S    \n",
    "    n_samples += 1\n",
    "    \n",
    "S_welch /= n_samples    \n",
    "print(\" Done!\")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "min_freq = 0.35\n",
    "max_freq = 0.7\n",
    "num_plots = 10\n",
    "\n",
    "start_freq_ii = np.argmin( np.abs(f-min_freq) )\n",
    "end_freq_ii = np.argmin( np.abs(f-max_freq) )\n",
    "indices = np.round( np.linspace(start_freq_ii, end_freq_ii, num_plots ) ).astype(np.uint32)\n",
    "\n",
    "print(\"  Generating plots\")\n",
    "kk=0\n",
    "for ii in tqdm(indices):\n",
    "\n",
    "    plt.figure( figsize=(11,10))    \n",
    "\n",
    "    #dummy = np.flipud( 2* np.mean(S_welch[ mdt+ii-1:mdt+ii+2,:,:], axis=0) )    \n",
    "    dummy = 2* np.mean(S_welch[ ii-1:ii+2,:,:], axis=0) \n",
    "    \n",
    "    dummy_cen = np.copy(dummy)\n",
    "    dummy_cen[ int(dummy_cen.shape[0]/2)-1:int(dummy_cen.shape[0]/2)+1, int(dummy_cen.shape[1]/2)-1:int(dummy_cen.shape[1]/2)+1 ] = 0\n",
    "    maxidx = np.unravel_index( np.argmax(dummy_cen), dummy_cen.shape )\n",
    "    \n",
    "    qp=( np.arctan2( KY[ maxidx[0],maxidx[1] ], KX[ maxidx[0],maxidx[1] ]) )/np.pi*180.0\n",
    "    if qp<0:\n",
    "        qp=qp+360\n",
    "\n",
    "    kp=np.sqrt( KX[ maxidx[0],maxidx[1] ]**2 + KY[ maxidx[0],maxidx[1] ]**2 )\n",
    "\n",
    "    plt.pcolor(KX,KY, 10*np.log10(dummy) )\n",
    "    plt.clim( 10*np.array([-5.0 + np.amax(np.log10(dummy)), -0+np.amax(np.log10(dummy))]) )\n",
    "    plt.colorbar()\n",
    "\n",
    "    #plt.scatter( [KX[ maxidx[0],maxidx[1] ]], [KY[ maxidx[0],maxidx[1] ]], marker=\"x\", s=100, c=\"k\" )\n",
    "\n",
    "    plt.ylim([-3.0,3.0])\n",
    "    plt.xlim([-3.0,3.0])\n",
    "\n",
    "    plt.xlabel(\"Kx (rad/m)\")\n",
    "    plt.ylabel(\"Ky (rad/m)\")\n",
    "    plt.title(\"S_kx_ky, fa=%3.2f (Hz).\\n Peak angle: %3.0f°, mag: %2.3f (rad/m)\\n\"%( f[ii],qp,kp ) )\n",
    "    kk+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('nonlocalinterp': conda)"
  },
  "interpreter": {
   "hash": "89510f71dc3970a8f0f8eef00689b1d269db9a35cf02b2be9ca2e3231486ff97"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}