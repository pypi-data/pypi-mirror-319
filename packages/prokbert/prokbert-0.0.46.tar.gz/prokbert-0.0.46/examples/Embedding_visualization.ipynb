{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3d2a41-506d-48a0-aac7-2b0ef7f3f680",
   "metadata": {},
   "source": [
    "# Sequence Representation Visualization with ProkBERT\n",
    "\n",
    "This guide outlines the steps to visualize sequence embeddings using ProkBERT, specifically focusing on the genomic features of ESKAPE pathogens with ProkBERT-mini. \n",
    "The workflow:\n",
    "1. **Model Loading**: Load the ProkBERT model designed for genomic sequence analysis.\n",
    "2. **Dataset Preparation**: Ready your dataset for ProkBERT by performing necessary preprocessing.\n",
    "3. **Model Evaluation**: Process your dataset through ProkBERT to generate embeddings.\n",
    "4. **Results Visualization**: Visualize these embeddings to identify patterns and insights into the genomic features.\n",
    "\n",
    "In this example we are going to visualize different geneomic features of the ESKAPE pathogens using the ProkBERT-mini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6100a54-36aa-4ba8-ac84-c6eb37256de6",
   "metadata": {},
   "source": [
    "### Setup and Installation\n",
    "\n",
    "Before we start, let's ensure that all necessary libraries are installed for our project. This notebook uses packages, including `umap-learn` for dimensionality reduction and `seaborn` for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab99a9-5b88-47bb-9f44-74d8d8ca9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProkBERT\n",
    "!pip install git+https://github.com/nbrg-ppcu/prokbert\n",
    "# Ensure umap-learn is installed\n",
    "!pip install umap-learn\n",
    "# Ensure seaborn is installed for vis\n",
    "!pip install seaborn\n",
    "\n",
    "# Imports\n",
    "from prokbert.training_utils import get_default_pretrained_model_parameters, get_torch_data_from_segmentdb_classification\n",
    "from torch.utils.data import DataLoader\n",
    "from prokbert.prok_datasets import ProkBERTTrainingDatasetPT\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664d9ed-d2b3-4009-aad1-3ff0c0492054",
   "metadata": {},
   "source": [
    "## Enabling and testing the GPU (if you are using google colab)\n",
    "\n",
    "First, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d327ba7-bb1e-4bec-8e35-2add64c3a261",
   "metadata": {},
   "source": [
    "### Loading the model\n",
    "In this step, we'll utilize the MINI pretrained model of ProkBERT, focusing on the base model to extract sequence embeddings. It's important to match the model with the appropriate tokenizer, especially when loading directly from Hugging Face to ensure compatibility with tokenization parameters.\n",
    "\n",
    "**Embeddings:**\n",
    "\n",
    "Embeddings are dense vector representations of data, in this case, genomic sequences, where similar sequences are closer in the vector space. This representation allows the model to capture the context and semantic meanings of sequences, facilitating more effective analysis and comparison. By extracting embeddings from the ProkBERT model, we can leverage these rich, contextually informed representations for various bioinformatics applications, such as clustering, similarity searches, or as features for downstream machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ef6d4-b476-433e-8df5-b6a89f5acbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_path = 'neuralbioinfo/prokbert-mini'\n",
    "model, tokenizer = get_default_pretrained_model_parameters(\n",
    "    model_name=model_name_path, \n",
    "    model_class='MegatronBertModel', \n",
    "    output_hidden_states=False, \n",
    "    output_attentions=False,\n",
    "    move_to_gpu=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0549de3-cdc3-402b-8e00-051bc4475c50",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Preparation\n",
    "\n",
    "In this section, we download a preprocessed and filtered dataset from Hugging Face. The dataset is then converted into a pandas DataFrame for easy manipulation and analysis. To efficiently manage memory and computation, especially when working with large datasets, we sample a subset (`Nsample`) of the original data. \n",
    "\n",
    "Further, we prepare the data for model training and evaluation by creating a PyTorch dataset. This involves tokenizing the sequences and formatting the data according to the requirements of our ProkBERT model. The `batch_size` parameter is crucial here, as it determines the number of samples to process in a single batch. Adjusting `batch_size` is essential for optimizing GPU usage, ensuring that the model training or evaluation process is both efficient and within the memory limits of your hardware.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b012ab-582f-4ed4-81f6-144f44af7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size for DataLoader and sample size\n",
    "batch_size=64\n",
    "Nsample=1000\n",
    "# Load the dataset from Hugging Face datasets library\n",
    "dataset = load_dataset(\"neuralbioinfo/ESKAPE-genomic-features\")\n",
    "eskape = dataset['ESKAPE'].to_pandas()\n",
    "eskape_features_sample = eskape.sample(1000)\n",
    "eskape_features_sample['y']=0\n",
    "\n",
    "# Prepare the data for PyTorch model training/evaluation\n",
    "[X, y, torchdb] = get_torch_data_from_segmentdb_classification(tokenizer, eskape_features_sample)\n",
    "ds = ProkBERTTrainingDatasetPT(X, y, AddAttentionMask=True)\n",
    "eval_dataloader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03167c3-2942-4640-a57f-9ece99901a03",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluating the Dataset\n",
    "\n",
    "Next, we will execute a forward pass to obtain the output embeddings from the last layer. The output dimension is \\( \\text{batch size} \\times \\text{sequence length} \\times \\text{embedding size} \\). To assign one vector to each sequence, rather than to each token, we need to aggregate the vectors. Here, we apply a simple mean function across the sequence length dimension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd937aa3-18df-4ae2-8ca9-2226be4eda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "representations = []\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    batch.pop('labels')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        mean_pooled = torch.mean(last_hidden_states, dim=1)        \n",
    "        # Optionally detach and move to CPU if you're planning to work with numpy or save memory on GPU\n",
    "        representations_batch = mean_pooled.detach().cpu().numpy()\n",
    "        representations.append(representations_batch)\n",
    "representations = np.concatenate(representations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b60f1e-e418-49ef-b2c4-208fca5fb8d4",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "In this section, we will visualize the high-dimensional representations using Uniform Manifold Approximation and Projection (UMAP). UMAP helps in visualizing complex datasets by projecting them into a lower-dimensional space, typically 2D or 3D, while preserving the original data's global and local structure as much as possible.\n",
    "\n",
    "**UMAP Parameters:**\n",
    "\n",
    "- **`n_neighbors`**: Controls how UMAP balances local versus global structure in the data. It determines the number of neighboring points used in local approximations of manifold structure. Higher values can help preserve more of the global structure.\n",
    "- **`min_dist`**: Sets the minimum distance between points in the low-dimensional representation. Smaller values allow UMAP to focus on finer details, while larger values help to preserve the broader data topology.\n",
    "- **`random_state`**: Ensures reproducibility of your results by fixing the random seed used by UMAP's stochastic optimization process.\n",
    "\n",
    "**Visualization Process:**\n",
    "\n",
    "Following the dimensionality reduction with UMAP, we will plot the embeddings, categorizing them by specific features (e.g., \"strand\" and \"label\") to observe how these characteristics distribute across the 2D space. This visualization can uncover patterns, similarities, and differences within the data, providing insights that are not readily apparent in the high-dimensional space.\n",
    "\n",
    "**Fine-Tuning UMAP Parameters:**\n",
    "\n",
    "Fine-tuning UMAP's parameters is crucial for achieving meaningful visualizations. Here's how to approach it:\n",
    "\n",
    "- **Exploring `n_neighbors`**: Start with a value around 10-50 and adjust based on your dataset's size and complexity. Smaller datasets or those with intricate structures may require adjusting this parameter to better capture the data's nuances.\n",
    "- **Adjusting `min_dist`**: Experiment with values between 0 and 0.99. A smaller `min_dist` allows UMAP to create more focused clusters, ideal for identifying subtle groupings or patterns in the data.\n",
    "- **Setting `random_state`**: Use a fixed value if you need consistent output across multiple runs, essential for comparative analysis or publication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609836ef-40ab-4c65-9158-55a7c4952bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_random_state = 42\n",
    "n_neighbors=20\n",
    "min_dist = 0.4\n",
    "\n",
    "eskape_embd = torchdb.merge(eskape, how='left', left_on='segment_id', right_on='segment_id')\n",
    "\n",
    "reducer = umap.UMAP(random_state=umap_random_state, n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "print('Running UMAP ....')\n",
    "umap_embeddings = reducer.fit_transform(representations)\n",
    "eskape_embd['umap_1']=umap_embeddings[:, 0]\n",
    "eskape_embd['umap_2']=umap_embeddings[:, 1]\n",
    "\n",
    "g = sns.FacetGrid(eskape_embd, col=\"strand\", hue=\"label\", palette=\"Set1\", height=6)\n",
    "# Apply a scatterplot to each subplot\n",
    "g.map(sns.scatterplot, \"umap_1\", \"umap_2\")\n",
    "# Add a legend\n",
    "g.add_legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4288385-791f-4b6c-a92a-5205bad36e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
