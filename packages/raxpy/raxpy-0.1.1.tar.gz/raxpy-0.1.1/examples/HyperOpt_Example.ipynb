{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import raxpy\n",
    "import raxpy.adapters.hyperopt as rhp\n",
    "from hyperopt import fmin, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" This Module conducts Parameter... TODO **unknown** \"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Annotated, Optional, Union\n",
    "\n",
    "\"\"\"\n",
    " - optional parameters\n",
    " - hierarchical parameters\n",
    " - combination parameters\n",
    " - higher-order interaction parameters\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OptimizerSGD:\n",
    "    \"\"\"\n",
    "    TODO Explain Class\n",
    "\n",
    "    **Not Implemented**\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class Layer:\n",
    "    number_hidden_units:Annotated[float, raxpy.Float()]\n",
    "    weight_init_technique:Annotated[int, raxpy.Integer(value_set=[0,1])]\n",
    "    epochs:Annotated[int, raxpy.Integer(lb=1, ub=100000)]\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RandomForestTrainer:\n",
    "    \"\"\"\n",
    "    TODO Explain Class\n",
    "\n",
    "    **Not Implemented**\n",
    "    \"\"\"\n",
    "    n_estimators:Annotated[int, raxpy.Integer(lb=20, ub=200)]\n",
    "    max_depth:Annotated[int, raxpy.Integer(lb=5, ub=20)]\n",
    "\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class SvmTrainer:\n",
    "    \"\"\"\n",
    "    TODO Explain Class\n",
    "\n",
    "    **Not Implemented**\n",
    "    \"\"\"\n",
    "    C:Annotated[int, raxpy.Float(lb=1e-3, ub=1e3)]\n",
    "    kernel:Annotated[int, raxpy.Integer(lb=5, ub=20)]\n",
    "\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class FeedForwardNetworkTrainer:\n",
    "\n",
    "    batch_size:Annotated[int, raxpy.Integer(value_set=[16,32,64,128])]\n",
    "    optimzer:OptimizerSGD\n",
    "    layer_1:Layer\n",
    "    layer_2:Optional[Layer]\n",
    "    layer_3:Optional[Layer]\n",
    "\n",
    "\n",
    "def train(\n",
    "    technique: RandomForestTrainer | SvmTrainer, # | FeedForwardNetworkTrainer,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    **Explain the Function**\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    technique_conf: Type: RandomForestTrainer | LinearRegressionTrainer\n",
    "        **Explanation**\n",
    "    preprocessing_conf\n",
    "        **Explanation**\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Not Implemented\n",
    "\n",
    "    \"\"\"\n",
    "    model = technique.train(x_train, y_train)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    pass\n",
    "\n",
    "def optimize(\n",
    "        init_sampling_points:Annotated[int, raxpy.Integer(lb=0, ub=50)],\n",
    "        designer,\n",
    "        max_points=100,\n",
    "        f=train,\n",
    "    ):\n",
    "\n",
    "    if init_sampling_points > 0:\n",
    "        input_space = raxpy.function_spec.extract_input_space(f)\n",
    "        design = designer(input_space, init_sampling_points)\n",
    "        inputs = rhp.convert_design(design)\n",
    "    else:\n",
    "        inputs = []\n",
    "\n",
    "    space, fn = rhp.convert_to_hp(f)\n",
    "\n",
    "    best = fmin(\n",
    "        fn=fn,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_points,\n",
    "        points_to_evaluate=inputs,\n",
    "    )\n",
    "\n",
    "    return (best, fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_f(\n",
    "    x1:Annotated[float, raxpy.Float(lb=-1.0, ub=1.0)],\n",
    "    x2:Annotated[float, raxpy.Float(lb=-1.0, ub=1.0)],\n",
    "):\n",
    "    return x1 * x2 + x1**2 - (2*x2 - 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = simple_f\n",
    "max_points = 20\n",
    "init_points = 10\n",
    "results = []\n",
    "results_2 = []\n",
    "for i in range(100):\n",
    "\n",
    "    point_1,fn = optimize(init_sampling_points=10, designer=raxpy.generate_design, f=f, max_points=max_points)\n",
    "    point_2,fn = optimize(init_sampling_points=10, designer=raxpy.generate_random_design, f=f, max_points=max_points)\n",
    "    point_3,fn = optimize(init_sampling_points=0, designer=raxpy.generate_random_design, f=f, max_points=max_points+init_points)\n",
    "\n",
    "    p1_b = fn(point_1)\n",
    "    r = p1_b < fn(point_2)\n",
    "\n",
    "    r2 = p1_b < fn(point_3)\n",
    "\n",
    "    results_2.append(r2)\n",
    "\n",
    "    results.append(r)\n",
    "    print(r)\n",
    "\n",
    "print(sum(1 for r in results if r)/len(results))\n",
    "print(sum(1 for r in results_2 if r)/len(results))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_f(-0.02080074739090043,0.9884268769655316 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_f(-0.5661405572959597,0.9974863142635275 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
