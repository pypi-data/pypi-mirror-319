from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled
import os
from pydub import AudioSegment
from speechkit import configure_credentials, creds
from speechkit import model_repository
from speechkit.stt import AudioProcessingType
import pathlib
from dotenv import load_dotenv

from src.ytb2audiobot.gpt import promt_gpt


async def get_subtitles(movie_id):
    try:
        transcript = YouTubeTranscriptApi.get_transcript(movie_id, languages=['ru'])
    except TranscriptsDisabled:
        print('‚õîÔ∏è YouTubeTranscriptApi: TranscriptsDisabled')
        return
    except (ValueError, Exception):
        print('‚õîÔ∏è Undefined problem in YouTubeTranscriptApi')
        return

    subtitles = [[entry['start'], entry['text']] for entry in transcript]
    return subtitles


def time_to_seconds(time_str):
    hours, minutes, seconds = map(int, time_str.split_by_duration(':'))
    return hours * 3600 + minutes * 60 + seconds


def filter_subtitles(subtitles, time_mark, time_delta):
    time_borders = [time_mark - time_delta, time_mark + time_delta]
    filtered_data = [entry for entry in subtitles if time_borders[0] <= entry[0] <= time_borders[1]]
    return filtered_data


async def convert_m4a_to_ogg(path):
    path = pathlib.Path(path)
    audio = AudioSegment.from_file(path.as_posix(), format="m4a")
    ogg_path = path.with_suffix('.ogg')
    audio.export(ogg_path.as_posix(), format="ogg")
    return ogg_path


async def voice2text(path):
    load_dotenv()

    yandex_bot_token = os.getenv('YANDEX_CLOUD_SPEACH_API_TOKEN')

    if not yandex_bot_token or len(yandex_bot_token) < 10:
        return

    configure_credentials(
        yandex_credentials=creds.YandexCredentials(
            api_key=yandex_bot_token
        )
    )

    path = pathlib.Path(path)
    model = model_repository.recognition_model()
    model.model = 'general'
    model.language = 'ru-RU'
    model.audio_processing_type = AudioProcessingType.Full

    result = model.transcribe_file(path.as_posix())
    return result


async def voice2text_processor(path):
    results = await voice2text(path)
    if not results:
        return

    data = []
    for c, res in enumerate(results):
        utterances = []
        for utterance in res.utterances:
            utterances.append(str(utterance))
        print('utterances: ')
        print(utterances)

        item = {
            'channel': c,
            'raw_text': res.raw_text,
            'normalized_text': res.normalized_text,
            'words': res.words,
            'utterances': utterances
        }
        data.append(item)
    return data


async def recogniser_trsinscript(original_audio_small_path):
    ogg_path = await convert_m4a_to_ogg(original_audio_small_path)
    if not ogg_path:
        return

    trans = await voice2text_processor(ogg_path)
    if not trans:
        return

    trans_normal = trans[0].get('normalized_text')

    if not trans_normal:
        return

    return trans_normal


SMALL_ORIRGINAL_PATH = 'pustovit-quote.m4a'

async def quote_designer(movie_id, time_mark_raw, time_delta):
    subtitles = await get_subtitles(movie_id)
    if not subtitles:
        return

    time_mark = time_to_seconds(time_mark_raw)
    subtitles_segments = filter_subtitles(subtitles, time_mark, time_delta)

    if not subtitles_segments:
        return
    print(subtitles_segments)

    fine_subtitles_list = [item[1] for item in subtitles_segments]
    fine_subtitles = '\n'.join(fine_subtitles_list)
    print('üíê: ', fine_subtitles)

    inst = '–≠—Ç–æ —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ youtube –≤–∏–¥–µ–æ. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π –Ω–µ—Å–∏–ª—å–Ω–æ —ç—Ç–∏ —Å—É–±—Ç–∏—Ç—Ä—ã. –í –º–µ—Å—Ç–∞—Ö, –≥–¥–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ —Å–ª–æ–≤–æ –ø–æ —Å–º—ã—Å–ª—É –ø–æ—Å—Ç–∞–≤—Ç—å —Ç—Ä–æ–µ—Ç–æ—á–∏–µ. –í –æ—Ç–≤–µ—Ç–µ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö —Å–ª—É–∂–µ–±–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.'
    gpt_ytb_subtitles_text = promt_gpt(inst, fine_subtitles, temperature=0.4)
    if not gpt_ytb_subtitles_text:
        return fine_subtitles

    recong_trans = await recogniser_trsinscript(SMALL_ORIRGINAL_PATH)
    if not recong_trans:
        return gpt_ytb_subtitles_text

    instruction = '–ù–µ—Å–∏–ª—å–Ω–æ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç. –†–∞–∑–¥–µ–ª–∏ –µ–≥–æ –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ –∞–±–∑–∞—Ü—ã. –í –æ—Ç–≤–µ—Ç–µ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö —Å–ª—É–∂–µ–±–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤'
    edited_trans = promt_gpt(instruction, recong_trans, temperature=0.4)
    if not edited_trans:
        return recong_trans

    return edited_trans
