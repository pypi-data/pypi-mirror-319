# coding: utf-8

"""
    SciCat backend API

    This is the API for the SciCat Backend

    The version of the OpenAPI document: api/v3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import Any, Dict, Optional
from pydantic import BaseModel, Field, StrictBool, StrictStr

class LifecycleClass(BaseModel):
    """
    LifecycleClass
    """
    archivable: Optional[StrictBool] = Field(default=None, description="Flag indicating if dataset is available to be archived and no archive job for this dataset exists yet.")
    retrievable: Optional[StrictBool] = Field(default=None, description="Flag indicating if dataset is stored on archive system and is ready to be retrieved.")
    publishable: Optional[StrictBool] = Field(default=None, description="Flag indicating if dataset can be published. Usually requires a longterm storage option on tape or similar.")
    date_of_disk_purging: Optional[datetime] = Field(default=None, alias="dateOfDiskPurging", description="Day when dataset will be removed from disk, assuming that is already stored on tape.")
    archive_retention_time: Optional[datetime] = Field(default=None, alias="archiveRetentionTime", description="Day when the dataset's future fate will be evaluated again, e.g. to decide if the dataset can be deleted from archive.")
    date_of_publishing: Optional[datetime] = Field(default=None, alias="dateOfPublishing", description="Day when dataset is supposed to become public according to data policy.")
    published_on: Optional[datetime] = Field(default=None, alias="publishedOn", description="Day when dataset was published.")
    is_on_central_disk: Optional[StrictBool] = Field(default=None, alias="isOnCentralDisk", description="Flag indicating if full dataset is available on central fileserver. If false, data needs to be copied from decentral storage places to a cache server before the ingest. This information needs to be transferred to the archive system at archive time.")
    archive_status_message: Optional[StrictStr] = Field(default='', alias="archiveStatusMessage", description="Short string defining the current status of the dataset with respect to storage on disk/tape.")
    retrieve_status_message: Optional[StrictStr] = Field(default='', alias="retrieveStatusMessage", description="Latest message for this dataset concerning retrieval from archive system.")
    archive_return_message: Optional[Dict[str, Any]] = Field(default=None, alias="archiveReturnMessage", description="Detailed status or error message returned by the archive system when archiving this dataset.")
    retrieve_return_message: Optional[Dict[str, Any]] = Field(default=None, alias="retrieveReturnMessage", description="Detailed status or error message returned by the archive system when retrieving this dataset.")
    exported_to: Optional[StrictStr] = Field(default=None, alias="exportedTo", description="Location of the last export destination.")
    retrieve_integrity_check: Optional[StrictBool] = Field(default=False, alias="retrieveIntegrityCheck", description="Set to true when checksum tests after retrieve of datasets were successful.")
    __properties = ["archivable", "retrievable", "publishable", "dateOfDiskPurging", "archiveRetentionTime", "dateOfPublishing", "publishedOn", "isOnCentralDisk", "archiveStatusMessage", "retrieveStatusMessage", "archiveReturnMessage", "retrieveReturnMessage", "exportedTo", "retrieveIntegrityCheck"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> LifecycleClass:
        """Create an instance of LifecycleClass from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self):
        """Returns the dictionary representation of the model using alias"""
        _dict = self.dict(by_alias=True,
                          exclude={
                          },
                          exclude_none=True)
        return _dict

    @classmethod
    def from_dict(cls, obj: dict) -> LifecycleClass:
        """Create an instance of LifecycleClass from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return LifecycleClass.parse_obj(obj)

        _obj = LifecycleClass.parse_obj({
            "archivable": obj.get("archivable"),
            "retrievable": obj.get("retrievable"),
            "publishable": obj.get("publishable"),
            "date_of_disk_purging": obj.get("dateOfDiskPurging"),
            "archive_retention_time": obj.get("archiveRetentionTime"),
            "date_of_publishing": obj.get("dateOfPublishing"),
            "published_on": obj.get("publishedOn"),
            "is_on_central_disk": obj.get("isOnCentralDisk"),
            "archive_status_message": obj.get("archiveStatusMessage") if obj.get("archiveStatusMessage") is not None else '',
            "retrieve_status_message": obj.get("retrieveStatusMessage") if obj.get("retrieveStatusMessage") is not None else '',
            "archive_return_message": obj.get("archiveReturnMessage"),
            "retrieve_return_message": obj.get("retrieveReturnMessage"),
            "exported_to": obj.get("exportedTo"),
            "retrieve_integrity_check": obj.get("retrieveIntegrityCheck") if obj.get("retrieveIntegrityCheck") is not None else False
        })
        return _obj


